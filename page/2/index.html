
<!DOCTYPE html>
<!--[if IEMobile 7 ]><html class="no-js iem7"><![endif]-->
<!--[if lt IE 9]><html class="no-js lte-ie8"><![endif]-->
<!--[if (gt IE 8)|(gt IEMobile 7)|!(IEMobile)|!(IE)]><!--><html class="no-js" lang="en"><!--<![endif]-->
<head>
  <meta charset="utf-8">
  <title>Edwin Chen's Blog</title>
  <meta name="author" content="Edwin Chen">

  
  <meta name="description" content="Introduction Suppose you ask a bunch of users to rate a set of movies on a 0-100 scale. In classical factor analysis, you could then try to explain &hellip;">
  

  <!-- http://t.co/dKP3o1e -->
  <meta name="HandheldFriendly" content="True">
  <meta name="MobileOptimized" content="320">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  
  <link rel="canonical" href="http://blog.echen.me/page/2">
  <link href="/favicon.png" rel="icon">
  <link href="/stylesheets/screen.css" media="screen, projection" rel="stylesheet" type="text/css">
  <script src="/javascripts/modernizr-2.0.js"></script>
  <script src="/javascripts/ender.js"></script>
  <script src="/javascripts/octopress.js" type="text/javascript"></script>
  <link href="/feed/" rel="alternate" title="Edwin Chen's Blog" type="application/atom+xml">
  <!--Fonts from Google"s Web font directory at http://google.com/webfonts -->
<link href="http://fonts.googleapis.com/css?family=PT+Serif:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">
<link href="http://fonts.googleapis.com/css?family=PT+Sans:regular,italic,bold,bolditalic" rel="stylesheet" type="text/css">

  
  <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-29005692-1']);
    _gaq.push(['_trackPageview']);

    (function() {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script>


</head>

<body   >
  <header role="banner"><hgroup>
  <h1><a href="/">Edwin Chen's Blog</a></h1>
  
</hgroup>

</header>
  <nav role="navigation"><ul class="subscription" data-subscription="rss">
  <li><a href="/feed/" rel="subscribe-rss" title="subscribe via RSS">RSS</a></li>
  
</ul>
  
<form action="http://google.com/search" method="get">
  <fieldset role="search">
    <input type="hidden" name="q" value="site:blog.echen.me" />
    <input class="search" type="text" name="q" results="0" placeholder="Search"/>
  </fieldset>
</form>
  
<ul class="main-navigation">
  <li><a href="/">Blog</a></li>
  <li><a href="/blog/archives">Archives</a></li>
</ul>

</nav>
  <div id="main">
    <div id="content">
      <div class="blog-index">
  
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2011/07/18/introduction-to-restricted-boltzmann-machines/">Introduction to Restricted Boltzmann Machines</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-07-18T09:32:52-07:00" pubdate data-updated="true">Jul 18<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>Introduction</h1>

<p>Suppose you ask a bunch of users to rate a set of movies on a 0-100 scale. In classical <a href="http://en.wikipedia.org/wiki/Factor_analysis">factor analysis</a>, you could then try to explain each movie and user in terms of a set of latent <em>factors</em>. For example, movies like Star Wars and Lord of the Rings might have strong associations with a latent science fiction and fantasy factor, and users who like Wall-E and Toy Story might have strong associations with a latent Pixar factor.</p>

<p>Restricted Boltzmann Machines essentially perform a <em>binary</em> version of factor analysis. (This is one way of thinking about RBMs; there are, of course, others, and lots of different ways to use RBMs, but I&#8217;ll adopt this approach for this post.) Instead of users rating a set of movies on a continuous scale, they simply tell you whether they like a movie or not, and the RBM will try to discover latent factors that can explain the activation of these movie choices.</p>

<p>More technically, a Restricted Boltzmann Machine is a <strong>stochastic neural network</strong> (<em>neural network</em> meaning we have neuron-like units whose binary activations depend on the neighbors they&#8217;re connected to; <em>stochastic</em> meaning these activations have a probabilistic element) consisting of:</p>

<ul>
<li>One layer of <strong>visible units</strong> (users&#8217; movie preferences whose states we know and set);</li>
<li>One layer of <strong>hidden units</strong> (the latent factors we try to learn); and</li>
<li>A bias unit (whose state is always on, and is a way of adjusting for the different inherent popularities of each movie).</li>
</ul>


<p>Furthermore, each visible unit is connected to all the hidden units (this connection is undirected, so each hidden unit is also connected to all the visible units), and the bias unit is connected to all the visible units and all the hidden units. To make learning easier, we restrict the network so that no visible unit is connected to any other visible unit and no hidden unit is connected to any other hidden unit.</p>

<p>For example, suppose we have a set of six movies (Harry Potter, Avatar, LOTR 3, Gladiator, Titanic, and Glitter) and we ask users to tell us which ones they want to watch. If we want to learn two latent units underlying movie preferences &#8211; for example, two natural groups in our set of six movies appear to be SF/fantasy (containing Harry Potter, Avatar, and LOTR 3) and Oscar winners (containing LOTR 3, Gladiator, and Titanic), so we might hope that our latent units will correspond to these categories &#8211; then our RBM would look like the following:</p>

<p><a href="http://dl.dropbox.com/u/10506/blog/rbms/rbm-example.png"><img src="http://dl.dropbox.com/u/10506/blog/rbms/rbm-example.png" alt="RBM Example" /></a></p>

<p>(Note the resemblance to a factor analysis graphical model.)</p>

<h1>State Activation</h1>

<p>Restricted Boltzmann Machines, and neural networks in general, work by updating the states of some neurons given the states of others, so let&#8217;s talk about how the states of individual units change. Assuming we know the connection weights in our RBM (we&#8217;ll explain how to learn these below), to update the state of unit $i$:</p>

<ul>
<li>Compute the <strong>activation energy</strong> $a_i = \sum_j w_{ij} x_j$ of unit $i$, where the sum runs over all units $j$ that unit $i$ is connected to, $w_{ij}$ is the weight of the connection between $i$ and $j$, and $x_j$ is the 0 or 1 state of unit $j$. In other words, all of unit $i$&#8217;s neighbors send it a message, and we compute the sum of all these messages.</li>
<li>Let $p_i = \sigma(a_i)$, where $\sigma(x) = 1/(1 + exp(-x))$ is the logistic function. Note that $p_i$ is close to 1 for large positive activation energies, and $p_i$ is close to 0 for negative activation energies.</li>
<li>We then turn unit $i$ on with probability $p_i$, and turn it off with probability $1 - p_i$.</li>
<li>(In layman&#8217;s terms, units that are positively connected to each other try to get each other to share the same state (i.e., be both on or off), while units that are negatively connected to each other are enemies that prefer to be in different states.)</li>
</ul>


<p>For example, let&#8217;s suppose our two hidden units really do correspond to SF/fantasy and Oscar winners.</p>

<ul>
<li>If Alice has told us her six binary preferences on our set of movies, we could then ask our RBM which of the hidden units her preferences activate (i.e., ask the RBM to explain her preferences in terms of latent factors). So the six movies send messages to the hidden units, telling them to update themselves. (Note that even if Alice has declared she wants to watch Harry Potter, Avatar, and LOTR 3, this doesn&#8217;t guarantee that the SF/fantasy hidden unit will turn on, but only that it will turn on with high <em>probability</em>. This makes a bit of sense: in the real world, Alice wanting to watch all three of those movies makes us highly suspect she likes SF/fantasy in general, but there&#8217;s a small chance she wants to watch them for other reasons. Thus, the RBM allows us to <em>generate</em> models of people in the messy, real world.)</li>
<li>Conversely, if we know that one person likes SF/fantasy (so that the SF/fantasy unit is on), we can then ask the RBM which of the movie units that hidden unit turns on (i.e., ask the RBM to generate a set of movie recommendations). So the hidden units send messages to the movie units, telling them to update their states. (Again, note that the SF/fantasy unit being on doesn&#8217;t guarantee that we&#8217;ll always recommend all three of Harry Potter, Avatar, and LOTR 3 because, hey, not everyone who likes science fiction liked Avatar.)</li>
</ul>


<h1>Learning Weights</h1>

<p>So how do we learn the connection weights in our network? Suppose we have a bunch of training examples, where each training example is a binary vector with six elements corresponding to a user&#8217;s movie preferences. Then for each epoch, do the following:</p>

<ul>
<li>Take a training example (a set of six movie preferences). Set the states of the visible units to these preferences.</li>
<li>Next, update the states of the hidden units using the logistic activation rule described above: for the $j$th hidden unit, compute its activation energy $a_j = \sum_i w_{ij} x_i$, and set $x_j$ to 1 with probability $\sigma(a_j)$ and to 0 with probability $1 - \sigma(a_j)$. Then for each edge $e_{ij}$, compute $Positive(e_{ij}) = x_i * x_j$ (i.e., for each pair of units, measure whether they&#8217;re both on).</li>
<li>Now <strong>reconstruct</strong> the visible units in a similar manner: for each visible unit, compute its activation energy $a_i$, and update its state. (Note that this <em>reconstruction</em> may not match the original preferences.) Then update the hidden units again, and compute $Negative(e_{ij}) = x_i * x_j$ for each edge.</li>
<li>Update the weight of each edge $e_{ij}$ by setting $w_{ij} = w_{ij} + L * (Positive(e_{ij}) - Negative(e_{ij}))$, where $L$ is a learning rate.</li>
<li>Repeat over all training examples.</li>
</ul>


<p>Continue until the network converges (i.e., the error between the training examples and their reconstructions falls below some threshold) or we reach some maximum number of epochs.</p>

<p>Why does this update rule make sense? Note that</p>

<ul>
<li>In the first phase, $Positive(e_{ij})$ measures the association between the $i$th and $j$th unit that we <em>want</em> the network to learn from our training examples;</li>
<li>In the &#8220;reconstruction&#8221; phase, where the RBM generates the states of visible units based on its hypotheses about the hidden units alone, $Negative(e_{ij})$ measures the association that the network <em>itself</em> generates (or &#8220;daydreams&#8221; about) when no units are fixed to training data.</li>
</ul>


<p>So by adding $Positive(e_{ij}) - Negative(e_{ij})$ to each edge weight, we&#8217;re helping the network&#8217;s daydreams better match the reality of our training examples.</p>

<p>(You may hear this update rule called <strong>contrastive divergence</strong>, which is basically a funky term for &#8220;approximate gradient descent&#8221;.)</p>

<h1>Examples</h1>

<p>I wrote <a href="https://github.com/echen/restricted-boltzmann-machines">a simple RBM implementation</a> in Python (the code is heavily commented, so take a look if you&#8217;re still a little fuzzy on how everything works), so let&#8217;s use it to walk through some examples.</p>

<p>First, I trained the RBM using some fake data.</p>

<ul>
<li>Alice: (Harry Potter = 1, Avatar = 1, LOTR 3 = 1, Gladiator = 0, Titanic = 0, Glitter = 0). Big SF/fantasy fan.</li>
<li>Bob: (Harry Potter = 1, Avatar = 0, LOTR 3 = 1, Gladiator = 0, Titanic = 0, Glitter = 0). SF/fantasy fan, but doesn&#8217;t like Avatar.</li>
<li>Carol: (Harry Potter = 1, Avatar = 1, LOTR 3 = 1, Gladiator = 0, Titanic = 0, Glitter = 0). Big SF/fantasy fan.</li>
<li>David: (Harry Potter = 0, Avatar = 0, LOTR 3 = 1, Gladiator = 1, Titanic = 1, Glitter = 0). Big Oscar winners fan.</li>
<li>Eric:  (Harry Potter = 0, Avatar = 0, LOTR 3 = 1, Gladiator = 1, Titanic = 1, Glitter = 0). Oscar winners fan, except for Titanic.</li>
<li>Fred: (Harry Potter = 0, Avatar = 0, LOTR 3 = 1, Gladiator = 1, Titanic = 1, Glitter = 0). Big Oscar winners fan.</li>
</ul>


<p>The network learned the following weights:</p>

<pre><code>                 Bias Unit       Hidden 1        Hidden 2
Bias Unit       -0.08257658     -0.19041546      1.57007782 
Harry Potter    -0.82602559     -7.08986885      4.96606654 
Avatar          -1.84023877     -5.18354129      2.27197472 
LOTR 3           3.92321075      2.51720193      4.11061383 
Gladiator        0.10316995      6.74833901     -4.00505343 
Titanic         -0.97646029      3.25474524     -5.59606865 
Glitter         -4.44685751     -2.81563804     -2.91540988
</code></pre>

<p>Note that the first hidden unit seems to correspond to the Oscar winners, and the second hidden unit seems to correspond to the SF/fantasy movies, just as we were hoping.</p>

<p>What happens if we give the RBM a new user, George, who has (Harry Potter = 0, Avatar = 0, LOTR 3 = 0, Gladiator = 1, Titanic = 1, Glitter = 0) as his preferences? It turns the Oscar winners unit on (but not the SF/fantasy unit), correctly guessing that George probably likes movies that are Oscar winners.</p>

<p>What happens if we activate only the SF/fantasy unit, and run the RBM a bunch of different times? In my trials, it turned on Harry Potter, Avatar, and LOTR 3 three times; it turned on Avatar and LOTR 3, but not Harry Potter, once; and it turned on Harry Potter and LOTR 3, but not Avatar, twice. Note that, based on our training examples, these generated preferences do indeed match what we might expect real SF/fantasy fans want to watch.</p>

<h1>Modifications</h1>

<p>I tried to keep the connection-learning algorithm I described above pretty simple, so here are some modifications that often appear in practice:</p>

<ul>
<li>Above, $Negative(e_{ij})$ was determined by taking the product of the $i$th and $j$th units after reconstructing the visible units <em>once</em> and then updating the hidden units again. We could also take the product after some larger number of reconstructions (i.e., repeat updating the visible units, then the hidden units, then the visible units again, and so on); this is slower, but describes the network&#8217;s daydreams more accurately.</li>
<li>Instead of using $Positive(e_{ij})=x_i * x_j$, where $x_i$ and $x_j$ are binary 0 or 1 <em>states</em>, we could also let $x_i$ and/or $x_j$ be activation <em>probabilities</em>. Similarly for $Negative(e_{ij})$.</li>
<li>We could penalize larger edge weights, in order to get a sparser or more regularized model.</li>
<li>When updating edge weights, we could use a momentum factor: we would add to each edge a weighted sum of the current step as described above (i.e., $L * (Positive(e_{ij}) - Negative(e_{ij})$) and the step previously taken.</li>
<li>Instead of using only one training example in each epoch, we could use <em>batches</em> of examples in each epoch, and only update the network&#8217;s weights after passing through all the examples in the batch. This can speed up the learning by taking advantage of fast matrix-multiplication algorithms.</li>
</ul>


<h1>Further</h1>

<p>If you&#8217;re interested in learning more about Restricted Boltzmann Machines, here are some good links.</p>

<ul>
<li><a href="http://www.cs.toronto.edu/~hinton/absps/guideTR.pdf">A Practical guide to training restricted Boltzmann machines</a>, by Geoffrey Hinton.</li>
<li>A talk by Andrew Ng on <a href="http://www.youtube.com/watch?v=ZmNOAtZIgIk">Unsupervised Feature Learning and Deep Learning</a>.</li>
<li><a href="http://www.machinelearning.org/proceedings/icml2007/papers/407.pdf">Restricted Boltzmann Machines for Collaborative Filtering</a>. I found this paper hard to read, but it&#8217;s an interesting application to the Netflix Prize.</li>
<li><a href="http://arxiv.org/abs/0908.4425">Geometry of the Restricted Boltzmann Machine</a>. A very readable introduction to RBMs, &#8220;starting with the observation that its Zariski closure is a Hadamard power of the first secant variety of the Segre variety of projective lines&#8221;. (I kid, I kid.)</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2011/07/09/visualizing-miss-usa-2011-should-evolution-be-taught-in-schools/">Visualizing Miss USA 2011: Should Evolution be Taught in Schools?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-07-09T13:02:05-07:00" pubdate data-updated="true">Jul 9<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><strong>tl;dr</strong> Should evolution be taught in schools? Go <a href="http://miss-usa-evolution.heroku.com">here</a> to visualize what the Miss USA contestants think.</p>

<h1>The Visualization</h1>

<p>Education is an area sorely in need of data crunching, so when I ran across <a href="http://www.youtube.com/watch?v=9QBv2CFTSWU&amp;feature=player_embedded#at=56">an amusing video</a> satirizing the Miss USA contestants&#8217; thoughts on teaching evolution, I thought it would be fun to transcribe <a href="youtube=http://www.youtube.com/watch?v=UkBmhM0R2A0&amp;feature=youtu.be#at=41">the original video</a> and visualize the data.</p>

<p>So after some tedious transcription, I built <a href="http://miss-usa-evolution.heroku.com">this app</a> to categorize and visualize the responses in various ways. (Mouseover states to see transcriptions, and click to jump to each contestant&#8217;s response in the video.)</p>

<h1>Example Maps</h1>

<p>Here are some examples of the generated maps.</p>

<p>First, we can look at which contestants believe in evolution (Miss California &#8211; the winner! &#8211; is the only contestant who explicitly states she believes in evolution; the red states explicitly state they do not believe in evolution; the grey states don&#8217;t make clear what they believe):</p>

<p><a href="http://miss-usa-evolution.heroku.com/?column=believes"><img src="http://dl.dropbox.com/u/10506/blog/miss-usa-evolution/believe-evolution.png" alt="Believe Evolution" /></a></p>

<p>We can also see which contestants believe evolution should be taught in schools (green states say yes, red states say no, grey states say maybe or that it should be a choice):</p>

<p><a href="http://miss-usa-evolution.heroku.com/?column=should_teach"><img src="http://dl.dropbox.com/u/10506/blog/miss-usa-evolution/teach-evolution.png" alt="Teach Evolution" /></a></p>

<p>Here is a rough Darwin-friendliness score I assigned to each response (worst in dark red to best in dark green):</p>

<p><a href="http://miss-usa-evolution.heroku.com/?column=score"><img src="http://dl.dropbox.com/u/10506/blog/miss-usa-evolution/score.png" alt="Score" /></a></p>

<p>This map shows which contestants believe schools should teach creationism:</p>

<p><a href="http://miss-usa-evolution.heroku.com/?column=teach_creationism"><img src="http://dl.dropbox.com/u/10506/blog/miss-usa-evolution/teach-creationism.png" alt="Teach Creationism" /></a></p>

<p>And this map shows which contestants mention science in their response:</p>

<p><a href="http://miss-usa-evolution.heroku.com/?column=mentions_science"><img src="http://dl.dropbox.com/u/10506/blog/miss-usa-evolution/mention-science.png" alt="Mention Science" /></a></p>

<p>So while there aren&#8217;t any striking patterns (I was hoping for a bright swath of red across the most religious states), the data&#8217;s still fun to look at, and it&#8217;s helpful to see that Alabama, whose <a href="http://www.youtube.com/watch?v=UkBmhM0R2A0&amp;feature=youtu.be#at=42">strongly anti-evolution</a> candidate is the only one colored red in both of the first two maps, does seem to be a bit of an outlier with respect to the rest of the nation.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2011/06/27/topic-modeling-the-sarah-palin-emails/">Topic Modeling the Sarah Palin Emails</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-06-27T17:19:42-07:00" pubdate data-updated="true">Jun 27<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><h1>LDA-based Email Browser</h1>

<p>Earlier this month, several thousand emails from Sarah Palin&#8217;s time as governor of Alaska were <a href="http://sunlightlabs.com/blog/2011/sarahs-inbox/">released</a>. The emails weren&#8217;t organized in any fashion, though, so to make them easier to browse, I&#8217;ve been working on some topic modeling (in particular, using latent Dirichlet allocation) to separate the documents into different groups.</p>

<p>I threw up <a href="http://sarah-palin.heroku.com/">a simple demo app</a> to view the organized documents <a href="http://sarah-palin.heroku.com/">here</a>.</p>

<h1>What is Latent Dirichlet Allocation?</h1>

<p>Briefly, given a set of documents, LDA tries to learn the latent topics underlying the set. It represents each document as a mixture of topics (generated from a Dirichlet distribution), each of which emits words with a certain probability.</p>

<p>For example, given the sentence &#8220;I listened to Justin Bieber and Lady Gaga on the radio while driving around in my car&#8221;, an LDA model might represent this sentence as 75% about music (a topic which, say, emits the words <em>Bieber</em> with 10% probability, <em>Gaga</em> with 5% probability, <em>radio</em> with 1% probability, and so on) and 25% about cars (which might emit <em>driving</em> with 15% probability and <em>cars</em> with 10% probability).</p>

<p>If you&#8217;re familiar with latent semantic analysis, you can think of LDA as a generative version. (For a more in-depth explanation, I wrote an introduction to LDA <a href="http://blog.echen.me/2011/08/22/introduction-to-latent-dirichlet-allocation/">here</a>.)</p>

<h1>Sarah Palin Email Topics</h1>

<p>Here&#8217;s a sample of the topics learnt by the model, as well as the top words for each topic. (Names, of course, are based on my own interpretation.)</p>

<ul>
<li><a href="http://sarah-palin.heroku.com/topics/24"><strong>Wildlife/BP Corrosion</strong></a>: game, fish, moose, wildlife, hunting, bears, polar, bear, subsistence, management, area, board, hunt, wolves, control, department, year, use, wolf, habitat, hunters, caribou, program, denby, fishing, …</li>
<li><a href="http://sarah-palin.heroku.com/topics/0"><strong>Energy/Fuel/Oil/Mining</strong></a>: energy, fuel, costs, oil, alaskans, prices, cost, nome, now, high, being, home, public, power, mine, crisis, price, resource, need, community, fairbanks, rebate, use, mining, villages, …</li>
<li><a href="http://sarah-palin.heroku.com/topics/19"><strong>Trig/Family/Inspiration</strong></a>: family, web, mail, god, son, from, congratulations, children, life, child, down, trig, baby, birth, love, you, syndrome, very, special, bless, old, husband, years, thank, best, …</li>
<li><a href="http://sarah-palin.heroku.com/topics/6"><strong>Gas</strong></a>: gas, oil, pipeline, agia, project, natural, north, producers, companies, tax, company, energy, development, slope, production, resources, line, gasline, transcanada, said, billion, plan, administration, million, industry, …</li>
<li><a href="http://sarah-palin.heroku.com/topics/12"><strong>Education/Waste</strong></a>: school, waste, education, students, schools, million, read, email, market, policy, student, year, high, news, states, program, first, report, business, management, bulletin, information, reports, 2008, quarter, …</li>
<li><a href="http://sarah-palin.heroku.com/topics/15"><strong>Presidential Campaign/Elections</strong></a>: mail, web, from, thank, you, box, mccain, sarah, very, good, great, john, hope, president, sincerely, wasilla, work, keep, make, add, family, republican, support, doing, p.o, …</li>
</ul>


<p>Here&#8217;s a sample email from the wildlife topic:</p>

<p><a href="http://sarah-palin.heroku.com/emails/6719"><img src="http://dl.dropbox.com/u/10506/blog/palin-browser/wildlife-email.png" alt="Wildlife Email" /></a></p>

<p>I also thought the classification for <a href="http://sarah-palin.heroku.com/emails/12900">this email</a> was really neat: the LDA model labeled it as 10% in the <a href="http://sarah-palin.heroku.com/topics/15">Presidential Campaign/Elections</a> topic and 90% in the <a href="http://sarah-palin.heroku.com/topics/24">Wildlife</a> topic, and it&#8217;s precisely a wildlife-based protest against Palin as a choice for VP:</p>

<p><a href="http://sarah-palin.heroku.com/emails/12900"><img src="http://dl.dropbox.com/u/10506/blog/palin-browser/wildlife-vp.png" alt="Wildlife-VP Protest" /></a></p>

<h1>Future Analysis</h1>

<p>In a future post, I&#8217;ll perhaps see if we can glean any interesting patterns from the email topics. For example, for a quick graph now, if we look at the percentage of emails in the <a href="http://sarah-palin.heroku.com/topics/19">Trig/Family/Inspiration topic</a> across time, we see that there&#8217;s a spike in April 2008 &#8211; exactly (and unsurprisingly) the month in which Trig was born.</p>

<p><a href="http://dl.dropbox.com/u/10506/blog/palin-browser/trig-topic.png"><img src="http://dl.dropbox.com/u/10506/blog/palin-browser/trig-topic.png" alt="Trig" /></a></p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2011/06/14/spork-spoon-or-fork/">Spork: Spoon or Fork?</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-06-14T23:32:04-07:00" pubdate data-updated="true">Jun 14<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>There&#8217;s <a href="http://www.youtube.com/watch?v=ruJ76-o5lxU">an adorable scene</a> in <em>WALL-E</em> where, unable to decide whether a spork belongs with his spoon collection or fork collection, WALL-E enters an infinite loop and spontaneously combusts*.</p>

<p><a href="http://dl.dropbox.com/u/10506/blog/spork/spork-indecision-2.gif"><img src="http://dl.dropbox.com/u/10506/blog/spork/spork-indecision-2.gif" alt="Spork" /></a></p>

<p>This led me to the following timeless question: is a spork more spoon or fork?</p>

<p>To answer, I did a little digging. First, I pulled images of spoons and forks from <a href="http://www.bing.com/images">Bing</a> (natch) and used these to train a spoon-vs.-fork SVM (using the excellent <a href="http://scikit-learn.sourceforge.net/">scikit-learn</a> package).</p>

<p>Using leave-one-out cross-validation, the classifier showed roughly 85% accuracy: 4 out of 20 spoons were misclassified as forks, and 2 out of 20 forks were misclassified as spoons. Not bad, considering the limited dataset and lack of tuning.</p>

<p>Finally, I applied the classifier to my spork images.</p>

<p>The results? 2 out of 20 sporks were classified as forks and the remaining 18 were classified as spoons, thereby definitively proving that <strong>a spork is 10% fork and 90% spoon</strong>.</p>

<p><a href="http://dl.dropbox.com/u/10506/blog/spork/spork-decomposition.png"><img src="http://dl.dropbox.com/u/10506/blog/spork/spork-decomposition.png" alt="Spork Decomposition" /></a></p>

<p>*Not really.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2011/05/05/twss-building-a-thats-what-she-said-classifier/">TWSS: Building a That&#8217;s What She Said Classifier</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-05-05T00:09:17-07:00" pubdate data-updated="true">May 5<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>There&#8217;s been a <a href="www.cs.washington.edu/homes/brun/pubs/pubs/Kiddon11.pdf">fun paper</a> on <a href="http://www.urbandictionary.com/define.php?term=that's%20what%20she%20said">That&#8217;s What She Said</a> identification making the rounds recently, so I spent some time over the weekend building my own classifier.</p>

<p><strong>tl;dr</strong> A simple unigram Naive Bayes model works pretty well, with performance on the lines of 0.969 precision and 0.823 recall. There&#8217;s a demo <a href="http://twss-classifier.heroku.com/">here</a>. I also ran the classifier over some fairy tale text.</p>

<h1>Naive Bayes Classifier</h1>

<p>To start, I used a super simple Naive Bayes classifier, trained on unigrams (with add-one smoothing). (See the appendix at the end for details.)</p>

<h2>Unigram vs. Bigram Model</h2>

<p>Here are the most predictive features, after training a Naive Bayes model with unigrams:</p>

<pre><code>unigram         p(twss|unigram)
pull            0.9724889822144924
bigger          0.9614677503890157
wet             0.959004244327654
hard            0.9527628206878138
stick           0.9505783678914388
hole            0.9443870318715991
oh              0.9432941279908561
replied         0.943294127990856
fast            0.943294127990856
longer          0.9397415371025485
</code></pre>

<p>Just to compare, here are some of the most predictive features in a bigram model (I added START and END tokens to the beginning and end of each sentence, in order to have some contextual features):</p>

<pre><code>bigram          p(twss|bigram)
it in           0.9801434151851175
START wow       0.9705079286853889
START oh        0.9473580156961879
its too         0.9350522640444204
pull out        0.9187779331523677
too big         0.9187779331523677
START man       0.9113755525471394
hard END        0.9113755525471394
put it          0.9071442285463515
that thing      0.9024886021363793
stick it        0.9024886021363793
my god          0.9024886021363793
go in           0.8916207044791409
START ugh       0.8916207044791409
make it         0.8916207044791409
its so          0.8916207044791409
</code></pre>

<p>Amusingly, sentences starting with <em>wow</em>, <em>oh</em>, and <em>ugh</em>, tend to be good candidates for TWSS sentences, as well as sentences containing <em>it&#8217;s too</em> and <em>it&#8217;s so</em>.</p>

<p>Here&#8217;s a precision-recall curve comparing the two models. We see that, on our datasets, a unigram classifier handily beats a bigram classifier:</p>

<p><a href="http://dl.dropbox.com/u/10506/blog/twss/precision-recall.png"><img src="http://dl.dropbox.com/u/10506/blog/twss/precision-recall.png" alt="Precision-Recall" /></a></p>

<h1>Darling it&#8217;s better</h1>

<p>Although our classifier gives excellent performance on our test set, one question is how well it generalizes to other sources of data.</p>

<p>I didn&#8217;t have another set of positive examples to draw from, but I took a set of fairy tales on Project Gutenberg to form a new batch of negative examples. On this new set of fairy tale sentences, the classifier misclassified only 81 out of 912 of the examples (assuming they should all be classified as &#8220;not TWSS&#8221;), which is a pretty low error rate of 8.89%.</p>

<p>What do these misclassifications look like? Here are some of the false positives it made:</p>

<h2>Aladdin</h2>

<ul>
<li>&#8220;The African magician carries it carefully wrapt up in his bosom,&#8221; said the princess; &#8220;and this I can assure you, because he pulled it out before me, and showed it to me in triumph.&#8221;</li>
<li>It is vanished; but I had no concern in its removal.</li>
<li>&#8220;My son,&#8221; said he, &#8220;what a man you are to do such surprising things always in the twinkling of an eye!&#8221;</li>
<li>&#8220;Sire,&#8221; replied Aladdin, &#8220;I have not the least reason to complain of your conduct, since you did nothing but what your duty required.&#8221;</li>
<li>&#8220;With your leave, mother,&#8221; replied Aladdin, &#8220;I shall now take care how I sell a lamp which may be so serviceable both to you and me.&#8221;</li>
</ul>


<p><a href="http://dl.dropbox.com/u/10506/blog/twss/aladdin.png"><img src="http://dl.dropbox.com/u/10506/blog/twss/aladdin.png" alt="http://dl.dropbox.com/u/10506/blog/twss/aladdin.png" /></a></p>

<h2>Hansel and Gretel</h2>

<ul>
<li>&#8220;Oh dear,&#8221; he said, &#8220;do let me go and see the hunt; I cannot restrain myself.&#8221;</li>
<li>When they awoke it was dark night, and poor Grethel began to cry, and said, &#8220;Oh, how shall we get out of the wood?&#8221; But Hansel comforted her.</li>
<li>&#8220;But remember,&#8221; she said, &#8220;I must lock the cottage door against those huntsmen, so when you come back in the evening, and knock, I shall not admit you, unless you say, &#8216;Dear little sister let me in.&#8217;</li>
</ul>


<h2>Snow White</h2>

<ul>
<li>One was too long, another too short; so she tried them all till she came to the seventh, and that was so comfortable that she laid herself down, and was soon fast asleep.</li>
<li>&#8220;Oh yes, I will try,&#8221; said Snow-white.</li>
</ul>


<p>Note that a lot of these really are TWSS sentences! (Now we know where <a href="http://www.snopes.com/disney/films/mermaid.asp">those Disney artists</a> got their inspiration.) So the classifier appears to generalize surprisingly well.</p>

<h1>A Demo</h1>

<p>I created <a href="http://twss-classifier.heroku.com/">a small Sinatra app</a> to play around with the classifier, and deployed it <a href="http://twss-classifier.heroku.com/">here</a>. I also put the code <a href="https://github.com/echen/twss-classifier">on Github</a>.</p>

<h1>Appendix: Details</h1>

<h2>Datasets</h2>

<p>To grab some TWSS examples, my first thought was to turn to <a href="http://search.twitter.com/search?q=twss">twitter</a>. However, the twitter data turned out to be incredibly noisy (lots of junk obscuring not terribly funny examples), so taking a cue from the K&amp;B paper, I pulled data from three sources:</p>

<ul>
<li>First, I scraped <a href="http://twssstories.com">twss stories</a> for positive training data (sentences for which a TWSS response is appropriate). Since only the last part in quotes from each submission is truly relevant to being a TWSS, I kept the quote and threw away the rest of each submission.</li>
<li>Next, I scraped <a href="http://textsfromlastnight.com">Texts from Last Night</a> and <a href="http://www.fmylife.com">FMyLife</a> for negative training data. Since TWSS jokes are usually made in response to <em>sentences</em> (the last sentence you say), I split each submission into sentences, and each sentence formed a single negative training example.</li>
</ul>


<p>Finally, I normalized each sentence by converting to lowercase and removing any punctuation.</p>

<h2>The Algorithm</h2>

<p>To train and test the classifier, I used the examples I gathered to form training and test sets, each consisting of:</p>

<ul>
<li>1000 positive examples from twss stories.</li>
<li>500 negative examples from Texts from Last Night.</li>
<li>500 negative examples from FMyLife.</li>
</ul>


<h2>Performance of the Unigram Model</h2>

<p>Since we want to optimize for precision (we hope the things we classify as TWSS sentences really are TWSS sentences) over recall (it&#8217;s fine if we don&#8217;t always respond TWSS to every TWSS sentence), let&#8217;s use 0.99 probability as our threshold for classifying a sentence as TWSS. (This is equivalent to setting a low prior for the probability of being a TWSS.)</p>

<p>With this threshold, a unigram Naive Bayes classifier has the following performance on a test set:</p>

<ul>
<li>True positives: 823</li>
<li>False negatives: 177</li>
<li>True negatives: 974</li>
<li>False positives: 26</li>
<li>Precision = 0.969</li>
<li>Recall = 0.823</li>
</ul>

</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2011/05/01/unsupervised-language-detection-algorithms/">Filtering for English Tweets: Unsupervised Language Detection on Twitter</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-05-01T16:28:07-07:00" pubdate data-updated="true">May 1<span>st</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>(See a demo <a href="http://babel-fett.heroku.com/">here</a>.)</p>

<p>While working on a Twitter sentiment analysis project, I ran into the problem of needing to filter out all non-English tweets. (Asking the Twitter API for English-only tweets doesn&#8217;t seem to work, as it nonetheless returns tweets in Spanish, Portuguese, Dutch, Russian, and a couple other languages.)</p>

<p>Since I didn&#8217;t have any labeled data, I thought it would be fun to build an <strong>unsupervised</strong> language classifier. In particular, using an EM algorithm to build a naive Bayes model of English vs. non-English n-gram probabilities turned out to work quite well, so here&#8217;s a description.</p>

<h1>EM Algorithm</h1>

<p>Let&#8217;s recall the naive Bayes algorithm: given a tweet (a set of <em>character</em> n-grams), we estimate its language to be the language $L$ that maximizes</p>

<p>$$P(language = L | ngrams) \propto P(ngrams | language = L) P(language = L)$$</p>

<p>Thus, we need to estimate $P(ngram | language = L)$ and $P(language = L)$.</p>

<p>This would be easy <strong>if we knew the language of each tweet</strong>, since we could estimate</p>

<ul>
<li>$P(xyz| language = English)$ as #(number of times &#8220;xyz&#8221; is a trigram in the English tweets) / #(total trigrams in the English tweets)</li>
<li>$P(language = English)$ as the proportion of English tweets.</li>
</ul>


<p>Or, it would also be easy <strong>if we knew the n-gram probabilities for each language</strong>, since we could use Bayes&#8217; theorem to compute the language <em>probabilities</em> for each tweet, and then take a weighted variant of the previous paragraph.</p>

<p><strong>The problem is that we know neither of these.</strong> So what the EM algorithm says is that that we can simply <strong>guess</strong>:</p>

<ul>
<li>Pretend we know the language of each tweet (by randomly assigning them at the beginning).</li>
<li>Using this guess, we can compute the n-gram probabilities for each language.</li>
<li>Using the n-gram probabilities for each language, we can recompute the language probabilities of each tweet.</li>
<li>Using these recomputed language probabilities, we can recompute the n-gram probabilities.</li>
<li>And so on, recomputing the language probabilities and n-gram probabilities over and over. While our guesses will be off in the beginning, the probabilities will eventually converge to (locally) minimize the likelihood. (In my tests, my language detector would sometimes correctly converge to an English detector, and sometimes it would converge to an English-and-Dutch detector.)</li>
</ul>


<h2>EM Analogy for the Layman</h2>

<p>Why does this work? Suppose you suddenly move to New York, and you want a way to differentiate between tourists and New Yorkers based on their activities. Initially, you don&#8217;t know who&#8217;s a tourist and who&#8217;s a New Yorker, and you don&#8217;t know which are touristy activities and which are not. So you randomly place people into two groups A and B. (You randomly assign all tweets to a language)</p>

<p>Now, given all the people in group A, you notice that a large number of them visit the Statue of Liberty; similarly, you notice that a large number of people in group B walk really quickly. (You notice that one set of words often has the n-gram &#8220;ing&#8221;, and that another set of words often has the n-gram &#8220;ias&#8221;; that is, you fix the language probabilities for each tweet, and recompute the n-gram probabilities for each language.)</p>

<p>So you start to put people visiting the Statue of Liberty in group A, and you start to put fast walkers in group B. (You fix the n-gram probabilities for each language, and recompute the language probabilities for each tweet.)</p>

<p>With your new A and B groups, you notice more differentiating factors: group A people tend to carry along cameras, and group B people tend to be more finance-savvy.</p>

<p>So you start to put camera-carrying folks in group A, and finance-savvy folks in group B.</p>

<p>And so on. Eventually, you settle on two groups of people and differentiating activities: people who walk slowly and visit the Statue of Liberty, and busy-looking people who walk fast and don&#8217;t visit. Assuming there are more native New Yorkers than tourists, you can then guess that the natives are the larger group.</p>

<h1>Results</h1>

<p>I wrote some Ruby code to implement the above algorithm, and trained it on half a million tweets, using English and &#8220;not English&#8221; as my two languages. The results looked surprisingly good from just eyeballing:</p>

<p><a href="https://img.skitch.com/20110303-qfrnb8gstgheh4xech4iutfskd.jpg"><img src="https://img.skitch.com/20110303-qfrnb8gstgheh4xech4iutfskd.jpg" alt="Example Results" /></a></p>

<p>But in order to get some hard metrics and to tune parameters (e.g., n-gram size), I needed a labeled dataset. So I pulled a set of English-language and Spanish-language documents from Project Gutenberg, and split them to form training and test sets (the training set consisted of 2000 lines of English and 1000 lines of Spanish, and  1000 lines of English and 1000 lines of Spanish for the test set).</p>

<p>Trained on bigrams, the detector resulted in:</p>

<ul>
<li>991 true positives (English lines correctly classified as English)</li>
<li>9 false negatives (English lines incorrectly classified as Spanish</li>
<li>11 false positives (Spanish lines incorrectly classified as English)</li>
<li>989 true negatives (Spanish lines correctly classified as English)</li>
</ul>


<p>for a precision of 0.989 and a recall of 0.991.</p>

<p>Trained on trigrams, the detector resulted in:</p>

<ul>
<li>992 true positives</li>
<li>8 false negatives</li>
<li>10 false positives</li>
<li>990 true negatives</li>
</ul>


<p>for a precision of 0.990 and a recall of 0.992.</p>

<p>Also, when I looked at the sentences the detector was making errors on, I saw that they almost always consisted of only one or two words (e.g., the incorrectly classified sentences were lines like &#8220;inmortal&#8221;, &#8220;autumn&#8221;, and &#8220;salir&#8221;). So the detector pretty much never made a mistake on a normal sentence!</p>

<h1>Code/Demo</h1>

<p>I put the code on <a href="https://github.com/echen/unsupervised-language-identification">my Github account</a>, and a quick <a href="http://babel-fett.heroku.com/">demo app</a>, trained on trigrams from tweets with lang=&#8221;en&#8221; according to the Twitter API, is <a href="http://babel-fett.heroku.com/">here</a>.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2011/05/01/eigensheep/">Eigensheep</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-05-01T15:23:31-07:00" pubdate data-updated="true">May 1<span>st</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>Aaron Koblin&#8217;s <a href="http://www.thesheepmarket.com/">Sheep Market</a> visualization is an awesome use of Mechanical Turk. But it&#8217;d be even more awesome if the grid were <em>ordered</em>, so I decided to try projecting the sheep onto two dimensions.</p>

<h1>Principal Sheep Components</h1>

<p>After screenshotting the first 50 sheep from the market and normalizing their size and color, here&#8217;s what a PCA projection looks like (<a href="http://dl.dropbox.com/u/10506/eigensheep.png">click</a> for a larger view):</p>

<p><a href="http://dl.dropbox.com/u/10506/eigensheep.png"><img src="http://dl.dropbox.com/u/10506/eigensheep.png" alt="Projected Sheep" /></a></p>

<p>Notice how the stroke widths get thicker as we move to the right (i.e., <strong>the first principal component seems to measure the blackness of the sheep</strong>), and the amount of wool on the sheep&#8217;s body increases as we move up (i.e., <strong>the second principal component seems to measure the wooliness of the sheep</strong>).</p>

<p>It&#8217;s also pretty neat how all the sheep with black heads and black legs (sheep 35, 16, 32, 31, and 19) get clumped together:</p>

<p><a href="http://dl.dropbox.com/u/10506/eigensheep-black-heads.png"><img src="http://dl.dropbox.com/u/10506/eigensheep-black-heads.png" alt="Projected Sheep, Black Heads/Legs Circled" /></a></p>

<p>And I think the sheep on the left (next to and inside the dense cluster) seem much more poorly drawn &#8211; they look more like camels, dogs, unicorns, or bugs than actual sheep.</p>

<h1>Code</h1>

<p>In a bit more detail, I used the poor man&#8217;s Mechanical Turk (myself) to screenshot the first 50 sheep from the market, trying to hug the sheep as closely as possible to ensure proper alignment. Next, I used the <a href="http://www.pythonware.com/products/pil/">Python Imaging Library</a> to resize the images to 150x150px, convert them to grayscale, and flatten them into the rows of a matrix.</p>

<p>In case anyone else wants to play with the sheep images, I put the <a href="https://github.com/echen/eigensheep">code</a> on my <a href="https://github.com/echen/eigensheep">Github</a> account.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2011/04/27/choosing-a-machine-learning-classifier/">Choosing a Machine Learning Classifier</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-04-27T18:43:15-07:00" pubdate data-updated="true">Apr 27<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>How do you know what machine learning algorithm to choose for your classification problem? Of course, if you really care about accuracy, your best bet is to test out a couple different ones (making sure to try different parameters within each algorithm as well), and select the best one by cross-validation. But if you&#8217;re simply looking for a &#8220;good enough&#8221; algorithm for your problem, or a place to start, here are some general guidelines I&#8217;ve found to work well over the years.</p>

<h1>How large is your training set?</h1>

<p>If your training set is small, high bias/low variance classifiers (e.g., Naive Bayes) have an advantage over low bias/high variance classifiers (e.g., kNN), since the latter will overfit. But low bias/high variance classifiers start to win out as your training set grows (they have lower asymptotic error), since high bias classifiers aren&#8217;t powerful enough to provide accurate models.</p>

<p>You can also think of this as a generative model vs. discriminative model distinction.</p>

<h1>Advantages of some particular algorithms</h1>

<p><strong>Advantages of Naive Bayes:</strong> Super simple, you&#8217;re just doing a bunch of counts. If the NB conditional independence assumption actually holds, a Naive Bayes classifier will converge quicker than discriminative models like logistic regression, so you need less training data. And even if the NB assumption doesn&#8217;t hold, a NB classifier still often does a great job in practice. A good bet if  want something fast and easy that performs pretty well. Its main disadvantage is that it can&#8217;t learn interactions between features (e.g., it can&#8217;t learn that although you love movies with Brad Pitt and Tom Cruise, you hate movies where they&#8217;re together).</p>

<p><strong>Advantages of Logistic Regression:</strong> Lots of ways to regularize your model, and you don&#8217;t have to worry as much about your features being correlated, like you do in Naive Bayes. You also have a nice probabilistic interpretation, unlike decision trees or SVMs, and you can easily update your model to take in new data (using an online gradient descent method), again unlike decision trees or SVMs. Use it if you want a probabilistic framework (e.g., to easily adjust classification thresholds, to say when you&#8217;re unsure, or to get confidence intervals) or if you expect to receive more training data in the future that you want to be able to quickly incorporate into your model.</p>

<p><strong>Advantages of Decision Trees:</strong> Easy to interpret and explain (for some people &#8211; I&#8217;m not sure I fall into this camp). They easily handle feature interactions and they&#8217;re non-parametric, so you don&#8217;t have to worry about outliers or whether the data is linearly separable (e.g., decision trees easily take care of cases where you have class A at the low end of some feature x, class B in the mid-range of feature x, and A again at the high end). One disadvantage is that they don&#8217;t support online learning, so you have to rebuild your tree when new examples come on. Another disadvantage is that they easily overfit, but that&#8217;s where ensemble methods like random forests (or boosted trees) come in. Plus, random forests are often the winner for lots of problems in classification (usually slightly ahead of SVMs, I believe), they&#8217;re fast and scalable, and you don&#8217;t have to worry about tuning a bunch of parameters like you do with SVMs, so they seem to be quite popular these days.</p>

<p><strong>Advantages of SVMs:</strong> High accuracy, nice theoretical guarantees regarding overfitting, and with an appropriate kernel they can work well even if you&#8217;re data isn&#8217;t linearly separable in the base feature space. Especially popular in text classification problems where very high-dimensional spaces are the norm. Memory-intensive, hard to interpret, and kind of annoying to run and tune, though, so I think random forests are starting to steal the crown.</p>

<h1>But&#8230;</h1>

<p>Recall, though, that better data often beats better algorithms, and designing good features goes a long way. And if you have a huge dataset, then whichever classification algorithm you use might not matter so much in terms of classification performance (so choose your algorithm based on speed or ease of use instead).</p>

<p>And to reiterate what I said above, if you really care about accuracy, you should definitely try a bunch of different classifiers and select the best one by cross-validation. Or, to take a lesson from the Netflix Prize (and Middle Earth), just use an ensemble method to choose them all.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2011/04/25/kickstarter-data-analysis-success-and-pricing/">Kickstarter Data Analysis: Success and Pricing</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-04-25T21:19:40-07:00" pubdate data-updated="true">Apr 25<span>th</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p><a href="http://www.kickstarter.com/">Kickstarter</a> is an online crowdfunding platform for launching creative projects. When starting a new project, project owners specify a deadline and the minimum amount of money they need to raise. They receive the money (less a transaction fee) only if they reach or exceed that minimum; otherwise, no money changes hands.</p>

<p>What&#8217;s particularly fun about Kickstarter is that in contrast to <a href="http://www.kiva.org/">that other microfinance site</a>, Kickstarter projects don&#8217;t ask for loans; instead, patrons receive pre-specified rewards unique to each project. For example, someone donating money to help an artist record an album might receive a digital copy of the album if they donate 20 dollars, or a digital copy plus a signed physical cd if they donate 50 dollars.</p>

<p>There are <a href="http://www.kickstarter.com/discover/hall-of-fame?ref=sidebar">a bunch</a> of <a href="http://www.kickstarter.com/projects/1104350651/tiktok-lunatik-multi-touch-watch-kits">neat</a> <a href="http://www.kickstarter.com/projects/2024077040/neil-gaimans-the-price">projects</a>, and I&#8217;m tempted to put one of my own on there soon, so I thought it would be fun to gather some data from the site and see what makes a project successful.</p>

<h1>Categories</h1>

<p>I started by scraping the categories section.</p>

<p><a href="http://dl.dropbox.com/u/10506/blog/kickstarter/successful-projects-by-category.png"><img src="http://dl.dropbox.com/u/10506/blog/kickstarter/successful-projects-by-category.png" alt="Successful projects by category" /></a></p>

<p>In true indie fashion, the artsy categories tend to dominate. (I&#8217;m surprised/disappointed how little love the Technology category gets.)</p>

<h1>Ending Soon</h1>

<p>The categories section really only provides a history of <em>successful</em> projects, though, so to get some data on unsuccessful projects as well, I took a look at the <a href="http://www.kickstarter.com/discover/ending-soon?ref=sidebar">Ending Soon</a> section of projects whose deadlines are about to pass.</p>

<p>It looks like about 50% of all Kickstarter projects get successfully funded by the deadline:</p>

<p><a href="http://dl.dropbox.com/u/10506/blog/kickstarter/ending-soon-success.png"><img src="http://dl.dropbox.com/u/10506/blog/kickstarter/ending-soon-success.png" alt="Successful projects as deadline approaches" /></a></p>

<p>Interestingly, most of the final funding seems to happen in the final few days: with just 5 days left, only about 20% of all projects have been funded. (In other words, with just 5 days left, 60% of the projects that will eventually be successful are still unfunded.) So the approaching deadline seems to really spur people to donate. I wonder if it&#8217;s because of increased publicity in the final few days (the project owners begging everyone for help!) or if it&#8217;s simply procrastination in action (perhaps people want to wait to see if their donation is really necessary)?</p>

<p>Lesson: if you&#8217;re still not fully funded with only a couple days remaining, don&#8217;t despair.</p>

<h1>Success vs. Failure</h1>

<p>What factors lead a project to succeed? Are there any quantitative differences between projects that eventually get funded and those that don&#8217;t?</p>

<p>Two simple (if kind of obvious) things I noticed are that unsuccessful projects tend to require a larger amount of money:</p>

<p><a href="http://dl.dropbox.com/u/10506/blog/kickstarter/successful-vs-unsuccessful-goal.png"><img src="http://dl.dropbox.com/u/10506/blog/kickstarter/successful-vs-unsuccessful-goal.png" alt="Unsuccessful projects tend to ask for more money" /></a></p>

<p>and unsuccessful projects also tend to raise less money in absolute terms (i.e., it&#8217;s not just that they ask for too much money to reach their goal &#8211; they&#8217;re simply not receiving enough money as well):</p>

<p><a href="http://dl.dropbox.com/u/10506/blog/kickstarter/successful-vs-unsuccessful-amount-pledged.png"><img src="http://dl.dropbox.com/u/10506/blog/kickstarter/successful-vs-unsuccessful-amount-pledged.png" alt="Unsuccessful projects received less money" /></a></p>

<p>Not terribly surprising, but it&#8217;s good to confirm (and I&#8217;m still working on finding other predictors).</p>

<h1>Pledge Rewards</h1>

<p>There&#8217;s a lot of interesting work in behavioral economics on pricing and choice &#8211; for example, the <a href="http://youarenotsosmart.com/2010/07/27/anchoring-effect/">anchoring effect</a> suggests that when building a menu, you should <a href="http://www.neurosciencemarketing.com/blog/articles/neuro-menus-and-restaurant-psychology.htm">include an expensive item</a> to make other menu items look reasonably priced in comparison, and the <a href="http://en.wikipedia.org/wiki/The_Paradox_of_Choice:_Why_More_Is_Less">paradox of choice </a> suggests that too many choices lead to a decision freeze &#8211; so one aspect of the Kickstarter data I was especially interested in was how pricing of rewards affects donations. For example, does pricing the lowest reward at 25 dollars lead to more money donated (people don&#8217;t lowball at 5 dollars instead) or less money donated (25 dollars is more money than most people are willing to give)? And what happens if a new reward at 5 dollars is added &#8211; again, does it lead to more money (now people can donate something they can afford) or less money (the people that would have paid 25 dollars switch to a 5 dollar donation)?</p>

<p>First, here&#8217;s a look at the total number of pledges at each price. (More accurately, it&#8217;s the number of claimed rewards at each price.) [Update: the original version of this graph was wrong, but I&#8217;ve since fixed it.]</p>

<p><a href="http://dl.dropbox.com/u/10506/blog/kickstarter/pledge%20amounts.png"><img src="http://dl.dropbox.com/u/10506/blog/kickstarter/pledge%20amounts.png" alt="Pledge Amounts" /></a></p>

<p>Surprisingly, 5 dollar and 1 dollar donations are actually not the most common contribution.</p>

<p>To investigate pricing effects, I started by looking at all (successful) projects that had a reward priced at 1 dollar, and compared the number of donations at 1 dollar with the number of donations at the next lowest reward.</p>

<p>Up to about 15-20 dollars, there&#8217;s a steady increase in the proportion of people who choose the second reward over the first reward, but after that, the proportion decreases.</p>

<p><a href="http://dl.dropbox.com/u/10506/blog/kickstarter/anchoring.png"><img src="http://dl.dropbox.com/u/10506/blog/kickstarter/anchoring.png" alt="Anchoring" /></a></p>

<p><a href="http://dl.dropbox.com/u/10506/blog/kickstarter/anchoring-abline-b.png"><img src="http://dl.dropbox.com/u/10506/blog/kickstarter/anchoring-abline-b.png" alt="Anchoring with Regression Lines" /></a></p>

<p>So this perhaps suggests that if you&#8217;re going to price your lowest reward at 1 dollar, your next reward should cost roughly 20 dollars (or slightly more, to maximize your total revenue). Pricing above 20 dollars is a little too expensive for the folks who want to support you, but aren&#8217;t rich enough to throw gads of money; maybe rewards below 20 dollars aren&#8217;t good enough to merit the higher donation.</p>

<p>Next, I&#8217;m planning on digging a little deeper into pricing effects and what makes a project successful, so I&#8217;ll hopefully have some more Kickstarter analysis in a future post. In the meantime, in case anyone else wants to take a look, I put the data onto <a href="https://github.com/echen/kickstarter-data-analysis">my Github account</a>.</p>
</div>
  
  


    </article>
  
  
    <article>
      
  <header>
    
      <h1 class="entry-title"><a href="/2011/04/21/a-mathematical-introduction-to-least-angle-regression/">A Mathematical Introduction to Least Angle Regression</a></h1>
    
    
      <p class="meta">
        








  


<time datetime="2011-04-21T00:16:36-07:00" pubdate data-updated="true">Apr 21<span>st</span>, 2011</time>
        
      </p>
    
  </header>


  <div class="entry-content"><p>(For a layman&#8217;s introduction, see <a href="http://blog.echen.me/2011/03/14/least-angle-regression-for-the-hungry-layman/">here</a>.)</p>

<p>Least Angle Regression (aka LARS) is a <strong>model selection method</strong> for linear regression (when you&#8217;re worried about overfitting or want your model to be easily interpretable). To motivate it, let&#8217;s consider some other model selection methods:</p>

<ul>
<li><strong>Forward selection</strong> starts with no variables in the model, and at each step it adds to the model the variable with the most explanatory power, stopping if the explanatory power falls below some threshold. This is a fast and simple method, but it can also be too greedy: we fully add variables at each step, so correlated predictors don&#8217;t get much of a chance to be included in the model. (For example, suppose we want to build a model for the deliciousness of a PB&amp;J sandwich, and two of our variables are the amount of peanut butter and the amount of jelly. We&#8217;d like both variables to appear in our model, but since amount of peanut butter is (let&#8217;s assume) strongly correlated with the amount of jelly, once we fully add peanut butter to our model, jelly doesn&#8217;t add much explanatory power anymore, and so it&#8217;s unlikely to be added.)</li>
<li><strong>Forward stagewise regression</strong> tries to remedy the greediness of forward selection by only partially adding variables. Whereas forward selection finds the variable with the most explanatory power and goes all out in adding it to the model, forward stagewise finds the variable with the most explanatory power and updates its weight by only epsilon in the correct direction. (So we might first increase the weight of peanut butter a little bit, then increase the weight of peanut butter again, then increase the weight of jelly, then increase the weight of bread, and then increase the weight of peanut butter once more.) The problem now is that we have to make a ton of updates, so forward stagewise can be very inefficient.</li>
</ul>


<p>LARS, then, is essentially forward stagewise made fast. Instead of making tiny hops in the direction of one variable at a time, LARS makes optimally-sized leaps in optimal directions. These directions are chosen to make equal angles (equal correlations) with each of the variables currently in our model. (We like peanut butter best, so we start eating it first; as we eat more, we get a little sick of it, so jelly starts looking equally appetizing, and we start eating peanut butter and jelly simultaneously; later, we add bread to the mix, etc.)</p>

<p>In more detail, LARS works as follows:</p>

<ul>
<li>Assume for simplicity that we&#8217;ve standardized our explanatory variables to have zero mean and unit variance, and that our response variable also has zero mean.</li>
<li>Start with no variables in your model.</li>
<li>Find the variable $ x_1 $ most correlated with the residual. (Note that the variable most correlated with the residual is equivalently the one that makes the least angle with the residual, whence the name.)</li>
<li>Move in the direction of this variable until some other variable $ x_2 $ is just as correlated.</li>
<li>At this point, start moving in a direction such that the residual stays equally correlated with $ x_1 $ and $ x_2 $ (i.e., so that the residual makes equal angles with both variables), and keep moving until some variable $ x_3 $ becomes equally correlated with our residual.</li>
<li>And so on, stopping when we&#8217;ve decided our model is big enough.</li>
</ul>


<p>For example, consider the following image (slightly simplified from the <a href="http://www.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf">original LARS paper</a>; $x_1, x_2$ are our variables, and $y$ is our response):</p>

<p><a href="http://dl.dropbox.com/u/10506/blog/lars/lars-example.png"><img src="http://dl.dropbox.com/u/10506/blog/lars/lars-example.png" alt="LARS Example" /></a></p>

<p>Our model starts at $ \hat{\mu_0} $.</p>

<ul>
<li>The residual (the green line) makes a smaller angle with $ x_1 $ than with $ x_2 $, so we start moving in the direction of $ x_1 $.
At $ \hat{\mu_1} $, the residual now makes equal angles with $ x_1, x_2 $, and so we start moving in a new direction that preserves this equiangularity/equicorrelation.</li>
<li>If there were more variables, we&#8217;d change directions again once a new variable made equal angles with our residual, and so on.</li>
</ul>


<p>So when should you use LARS, as opposed to some other regularization method like lasso? There&#8217;s not really a clear-cut answer, but LARS tends to give very similar results as both lasso and forward stagewise (in fact, slight modifications to LARS give you lasso and forward stagewise), so I tend to just use lasso when I do these kinds of things, since the justifications for lasso make a little more sense to me. In fact, I don&#8217;t usually even think of LARS as a model selection method in its own right, but rather as a way to efficiently implement lasso (especially if you want to compute the full regularization path).</p>
</div>
  
  


    </article>
  
  <div class="pagination">
    
      <a class="prev" href="/page/3/">&larr; Older</a>
    
    <a href="/blog/archives">Blog Archives</a>
    
    <a class="next" href="/">Newer &rarr;</a>
    
  </div>
</div>
<aside class="sidebar">
  
    <section>
  <h1>Edwin Chen</h1>
  
  <p>Data scientist at Twitter. Previously math and linguistics at MIT, quantitative trading at Clarium Capital.</p>
  
  <p>I like math, statistics, machine learning, and linguistics.</p>

  <p>Email: hello[at]echen.me<br/>
  Twitter: <a href="https://twitter.com/#!/edchedch">@edchedch</a><br/>
  Other: <a href="https://github.com/echen">Github</a>, <a href="https://plus.google.com/113804726252165471503/">Google+</a>, <a href="http://www.linkedin.com/in/edwinchen1">LinkedIn</a>, <a href="http://quora.com/edwin-chen-1">Quora</a></p>
</section><section>
  <h1>Recent Posts</h1>
  <ul id="recent_posts">
    
      <li class="post">
        <a href="/2012/03/20/infinite-mixture-models-with-nonparametric-bayes-and-the-dirichlet-process/">Infinite Mixture Models with Nonparametric Bayes and the Dirichlet Process</a>
      </li>
    
      <li class="post">
        <a href="/2012/03/05/instant-interactive-visualization-with-d3-and-ggplot2/">Instant interactive visualization with d3 + ggplot2</a>
      </li>
    
      <li class="post">
        <a href="/2012/02/09/movie-recommendations-and-more-via-mapreduce-and-scalding/">Movie recommendations and more via MapReduce and Scalding</a>
      </li>
    
      <li class="post">
        <a href="/2012/01/17/quick-introduction-to-ggplot2/">Quick Introduction to ggplot2</a>
      </li>
    
      <li class="post">
        <a href="/2012/01/03/introduction-to-conditional-random-fields/">Introduction to Conditional Random Fields</a>
      </li>
    
      <li class="post">
        <a href="/2011/10/24/winning-the-netflix-prize-a-summary/">Winning the Netflix Prize: A Summary</a>
      </li>
    
      <li class="post">
        <a href="/2011/09/29/stuff-harvard-people-like/">Stuff Harvard People Like</a>
      </li>
    
      <li class="post">
        <a href="/2011/09/07/information-transmission-in-a-social-network-dissecting-the-spread-of-a-quora-post/">Information Transmission in a Social Network: Dissecting the Spread of a Quora Post</a>
      </li>
    
      <li class="post">
        <a href="/2011/08/22/introduction-to-latent-dirichlet-allocation/">Introduction to Latent Dirichlet Allocation</a>
      </li>
    
      <li class="post">
        <a href="/2011/07/28/tweets-vs-likes-what-gets-shared-on-twitter-vs-facebook/">Tweets vs. Likes: What gets shared on Twitter vs. Facebook?</a>
      </li>
    
  </ul>
</section>

<section>
  <h1>Latest Tweets</h1>
  <ul id="tweets">
    <li class="loading">Status updating&#8230;</li>
  </ul>
  <script type="text/javascript">
    $.domReady(function(){
      getTwitterFeed("edchedch", 5, false);
    });
  </script>
  <script src="/javascripts/twitter.js" type="text/javascript"> </script>
  
    <a href="http://twitter.com/edchedch" class="twitter-follow-button" data-show-count="true">Follow @edchedch</a>
  
</section>


  
</aside>

    </div>
  </div>
  <footer role="contentinfo"><p>
  Copyright &copy; 2012 - Edwin Chen -
  <span class="credit">Powered by <a href="http://octopress.org">Octopress</a></span>
</p>

</footer>
  

<script type="text/javascript">
      var disqus_shortname = 'edwinchen';
      
        
        var disqus_script = 'count.js';
      
    (function () {
      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      dsq.src = 'http://' + disqus_shortname + '.disqus.com/' + disqus_script;
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    }());
</script>



<div id="fb-root"></div>
<script>(function(d, s, id) {
  var js, fjs = d.getElementsByTagName(s)[0];
  if (d.getElementById(id)) {return;}
  js = d.createElement(s); js.id = id;
  js.src = "//connect.facebook.net/en_US/all.js#appId=212934732101925&xfbml=1";
  fjs.parentNode.insertBefore(js, fjs);
}(document, 'script', 'facebook-jssdk'));</script>



  <script type="text/javascript">
    (function() {
      var script = document.createElement('script'); script.type = 'text/javascript'; script.async = true;
      script.src = 'https://apis.google.com/js/plusone.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(script, s);
    })();
  </script>



  <script type="text/javascript">
    (function(){
      var twitterWidgets = document.createElement('script');
      twitterWidgets.type = 'text/javascript';
      twitterWidgets.async = true;
      twitterWidgets.src = 'http://platform.twitter.com/widgets.js';
      document.getElementsByTagName('head')[0].appendChild(twitterWidgets);
    })();
  </script>





</body>
</html>

<!-- mathjax config similar to math.stackexchange -->
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  jax: ["input/TeX", "output/HTML-CSS"],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  messageStyle: "none",
  "HTML-CSS": { preferredFont: "TeX", availableFonts: ["STIX","TeX"] }
});
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML" type="text/javascript"></script>